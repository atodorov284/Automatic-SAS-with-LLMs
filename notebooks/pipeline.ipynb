{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "from transformers import pipeline\n",
    "\n",
    "dir =  os.path.abspath('../src')\n",
    "if dir not in sys.path:\n",
    "    sys.path.append(dir)\n",
    "        \n",
    "from prompt_creation import CreatePrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "login(token=os.getenv(\"HUGGINGFACE_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f616ba8f26c2465486a6283f0b074370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test = pd.read_csv(os.path.join(os.path.abspath(os.path.join('..')), \n",
    "                                  'data',\n",
    "                                  'predictions',\n",
    "                                  'test_set_with_predictions.csv'))\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"google/gemma-2-2b-it\",\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student answer: The procedures I think they should have included inorder for me to replicate the experiment would be how different samples did they used for each? What tool did they use to determine the mass.\n",
      "Assistant answer: ## Feedback on Student's Answer\n",
      "\n",
      "**General Score:** 1/4\n",
      "\n",
      "**Explanation:**  The student demonstrates a basic understanding of the need for additional information to replicate an experiment. However, the response is incomplete and lacks depth. The student identifies two key pieces of information but fails to provide a clear explanation of their importance. \n",
      "\n",
      "**Readability:** 71.14/100\n",
      "\n",
      "**Lexical Diversity:** 0.8235294117647058/1\n",
      "\n",
      "**General Feedback:** The student's answer shows a basic understanding of the concept of replication but lacks the depth and clarity required for a successful response. The student needs to demonstrate a deeper understanding of the experiment's purpose and the specific details needed to replicate it. \n",
      "\n",
      "**Specific Feedback:**\n",
      "\n",
      "* **Readability:** The student's response is grammatically correct and uses simple language. However, it lacks clarity and conciseness. The student could improve readability by using more specific and precise language. For example, instead of saying \"how different samples did they use for each?\", the student could ask \"What specific materials were used for each sample?\" \n",
      "* **Lexical Diversity:** The student's vocabulary is adequate but lacks variety. The student could improve lexical diversity by using more complex and varied vocabulary. For example, instead of saying \"tool\", the student could use \"instrument\" or \"measuring device\".\n",
      "* **Additional Information:** The student identifies two key pieces of information: the type of samples used and the method of mass determination. However, the student could provide more specific details about the type of samples used and the specific instrument used for mass determination. For example, the student could ask \"What type of wood, plastic, marble, and limestone were used?\" and \"What instrument was used to measure the mass?\"\n",
      "\n",
      "\n",
      "**Suggestions for Improvement:**\n",
      "\n",
      "* Encourage the student to think critically about the experiment and identify the specific details needed to replicate it.\n",
      "* Guide the student to use more precise and specific language when describing the information they need.\n",
      "* Provide examples of how to phrase questions in a clear and concise manner. \n",
      "* Encourage the student to use a variety of vocabulary to enhance their writing.\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "final_score = df_test['model_prediction'].iloc[pos]\n",
    "essay_set = df_test['EssaySet'].iloc[pos]\n",
    "readability = df_test['Readability'].iloc[pos]\n",
    "ttr = df_test['TTR'].iloc[pos]\n",
    "answer = df_test['EssayText'].iloc[pos]\n",
    "\n",
    "prompter = CreatePrompt()\n",
    "prompt = prompter.get_prompt(essay_set, final_score, readability, ttr, answer)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "\n",
    "outputs = pipe(messages, max_new_tokens=500)\n",
    "assistant_response = outputs[0][\"generated_text\"][-1][\"content\"].strip()\n",
    "print(f\"Student answer: {answer}\")\n",
    "print(f\"Real final score: {final_score}\")\n",
    "print(f\"Real readability: {readability}\")\n",
    "print(f\"Real TTR: {ttr}\")\n",
    "print(f\"Student answer: {answer}\")\n",
    "\n",
    "print(f\"Assistant answer: {assistant_response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
