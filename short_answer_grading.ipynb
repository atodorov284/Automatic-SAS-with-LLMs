{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the datasets and perform exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers[torch] transformers torch pandas numpy scikit-learn tqdm docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from datasets import load_from_disk, concatenate_datasets\n",
    "from transformers import (\n",
    "    BertForSequenceClassification,\n",
    "    BertTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "\n",
    "from bert_scoring_model import BertScoringModel\n",
    "\n",
    "\n",
    "from qwk import quadratic_weighted_kappa\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from score_essays import score_essay\n",
    "from copy import deepcopy\n",
    "from docx import Document\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train_rel_2.tsv\", sep=\"\\t\")\n",
    "test_data = pd.read_csv(\"data/public_leaderboard_rel_2.tsv\", sep=\"\\t\")\n",
    "test_data_scores = pd.read_csv(\"data/public_leaderboard_solution.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set descriptions and scores are in different files, need to be merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>EssaySet</th>\n",
       "      <th>EssayText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1673</td>\n",
       "      <td>1</td>\n",
       "      <td>The procedures I think they should have includ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1674</td>\n",
       "      <td>1</td>\n",
       "      <td>In order to replicate this experiment, you wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1675</td>\n",
       "      <td>1</td>\n",
       "      <td>In order to replicate their experiment, you wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1676</td>\n",
       "      <td>1</td>\n",
       "      <td>Pleace a simple of one material into one conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1677</td>\n",
       "      <td>1</td>\n",
       "      <td>Determin the mass of four different samples ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  EssaySet                                          EssayText\n",
       "0  1673         1  The procedures I think they should have includ...\n",
       "1  1674         1  In order to replicate this experiment, you wou...\n",
       "2  1675         1  In order to replicate their experiment, you wo...\n",
       "3  1676         1  Pleace a simple of one material into one conta...\n",
       "4  1677         1  Determin the mass of four different samples ma..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>EssaySet</th>\n",
       "      <th>EssayWeights</th>\n",
       "      <th>Score1</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1673</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PublicTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1674</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PublicTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1675</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>PublicTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1676</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PublicTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1677</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PublicTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  EssaySet  EssayWeights  Score1       Usage\n",
       "0  1673         1             1       1  PublicTest\n",
       "1  1674         1             1       1  PublicTest\n",
       "2  1675         1             1       3  PublicTest\n",
       "3  1676         1             1       0  PublicTest\n",
       "4  1677         1             1       0  PublicTest"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>EssaySet</th>\n",
       "      <th>EssayText</th>\n",
       "      <th>EssayWeights</th>\n",
       "      <th>Score1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1673</td>\n",
       "      <td>1</td>\n",
       "      <td>The procedures I think they should have includ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1674</td>\n",
       "      <td>1</td>\n",
       "      <td>In order to replicate this experiment, you wou...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1675</td>\n",
       "      <td>1</td>\n",
       "      <td>In order to replicate their experiment, you wo...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1676</td>\n",
       "      <td>1</td>\n",
       "      <td>Pleace a simple of one material into one conta...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1677</td>\n",
       "      <td>1</td>\n",
       "      <td>Determin the mass of four different samples ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  EssaySet                                          EssayText  \\\n",
       "0  1673         1  The procedures I think they should have includ...   \n",
       "1  1674         1  In order to replicate this experiment, you wou...   \n",
       "2  1675         1  In order to replicate their experiment, you wo...   \n",
       "3  1676         1  Pleace a simple of one material into one conta...   \n",
       "4  1677         1  Determin the mass of four different samples ma...   \n",
       "\n",
       "   EssayWeights  Score1  \n",
       "0             1       1  \n",
       "1             1       1  \n",
       "2             1       3  \n",
       "3             1       0  \n",
       "4             1       0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_data.merge(test_data_scores, on=['Id',  'EssaySet'],  how='left')\n",
    "test_data.drop('Usage', axis=1, inplace=True)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>EssaySet</th>\n",
       "      <th>Score1</th>\n",
       "      <th>EssayText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Some additional information that we would need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>After reading the expirement, I realized that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>What you need is more trials, a control set up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The student should list what rock is better an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>For the students to be able to make a replicat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  EssaySet  Score1                                          EssayText\n",
       "0   1         1       1  Some additional information that we would need...\n",
       "1   2         1       1  After reading the expirement, I realized that ...\n",
       "2   3         1       1  What you need is more trials, a control set up...\n",
       "3   4         1       0  The student should list what rock is better an...\n",
       "4   5         1       2  For the students to be able to make a replicat..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.drop('Score2', axis=1, inplace=True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>EssaySet</th>\n",
       "      <th>Score1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17043.000000</td>\n",
       "      <td>17043.000000</td>\n",
       "      <td>17043.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13820.561286</td>\n",
       "      <td>5.609576</td>\n",
       "      <td>0.926245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8256.441258</td>\n",
       "      <td>2.822468</td>\n",
       "      <td>0.893137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6275.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14270.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20928.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27588.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id      EssaySet        Score1\n",
       "count  17043.000000  17043.000000  17043.000000\n",
       "mean   13820.561286      5.609576      0.926245\n",
       "std     8256.441258      2.822468      0.893137\n",
       "min        1.000000      1.000000      0.000000\n",
       "25%     6275.500000      3.000000      0.000000\n",
       "50%    14270.000000      6.000000      1.000000\n",
       "75%    20928.500000      8.000000      2.000000\n",
       "max    27588.000000     10.000000      3.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Score1\n",
       "0    6731\n",
       "1    5579\n",
       "2    3992\n",
       "3     741\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Score1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>EssaySet</th>\n",
       "      <th>Score1</th>\n",
       "      <th>EssayText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Some additional information that we would need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>After reading the expirement, I realized that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>What you need is more trials, a control set up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The student should list what rock is better an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>For the students to be able to make a replicat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  EssaySet  Score1                                          EssayText\n",
       "0   1         1       1  Some additional information that we would need...\n",
       "1   2         1       1  After reading the expirement, I realized that ...\n",
       "2   3         1       1  What you need is more trials, a control set up...\n",
       "3   4         1       0  The student should list what rock is better an...\n",
       "4   5         1       2  For the students to be able to make a replicat..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation split and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ESSAY_SETS = max(train_data['EssaySet']) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docx_files_in_order(directory):\n",
    "    task_descriptions = {}\n",
    "    \n",
    "    filenames = [filename for filename in os.listdir(directory) if filename.startswith(\"Data Set\") and filename.endswith(\"--ReadMeFirst.docx\")]\n",
    "    \n",
    "    filenames.sort(key=lambda x: int(x.split('#')[1].split('--')[0].strip()))\n",
    "\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        doc = Document(file_path)\n",
    "        \n",
    "        text = []\n",
    "        for para in doc.paragraphs:\n",
    "            text.append(para.text.strip())\n",
    "            \n",
    "        task_descriptions[filename] = \"\\n\".join(text)\n",
    "    \n",
    "    ordered_descriptions = {i + 1: task_descriptions[filename] for i, filename in enumerate(filenames)}\n",
    "    \n",
    "    return ordered_descriptions\n",
    "\n",
    "directory_path = 'task_descriptions/'\n",
    "task_descriptions = load_docx_files_in_order(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Grading Scale'] = train_data.groupby('EssaySet')['Score1'].transform(lambda x: f\"{x.min()} to {x.max()}\")\n",
    "test_data['Grading Scale'] = test_data.groupby('EssaySet')['Score1'].transform(lambda x: f\"{x.min()} to {x.max()}\")\n",
    "\n",
    "train_data['EssayText'] = train_data.apply(lambda row: f\"Task description: {task_descriptions[row['EssaySet']]}. Grade this student's answer on a scale {row['Grading Scale']}, taking into account grammar, lexical variability, and task relevance. Student's answer: {row['EssayText']}\", axis=1)\n",
    "test_data['EssayText'] = test_data.apply(lambda row: f\"Grade this answer on a scale {row['Grading Scale']}: {row['EssayText']}\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>EssaySet</th>\n",
       "      <th>Score1</th>\n",
       "      <th>EssayText</th>\n",
       "      <th>Grading Scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Task description: Data Set #1\\nPrompt—Acid Rai...</td>\n",
       "      <td>0 to 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Task description: Data Set #1\\nPrompt—Acid Rai...</td>\n",
       "      <td>0 to 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Task description: Data Set #1\\nPrompt—Acid Rai...</td>\n",
       "      <td>0 to 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Task description: Data Set #1\\nPrompt—Acid Rai...</td>\n",
       "      <td>0 to 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Task description: Data Set #1\\nPrompt—Acid Rai...</td>\n",
       "      <td>0 to 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17038</th>\n",
       "      <td>27584</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Task description: Data Set #10\\nPrompt—Doghous...</td>\n",
       "      <td>0 to 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17039</th>\n",
       "      <td>27585</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Task description: Data Set #10\\nPrompt—Doghous...</td>\n",
       "      <td>0 to 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17040</th>\n",
       "      <td>27586</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Task description: Data Set #10\\nPrompt—Doghous...</td>\n",
       "      <td>0 to 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17041</th>\n",
       "      <td>27587</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Task description: Data Set #10\\nPrompt—Doghous...</td>\n",
       "      <td>0 to 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17042</th>\n",
       "      <td>27588</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Task description: Data Set #10\\nPrompt—Doghous...</td>\n",
       "      <td>0 to 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17043 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  EssaySet  Score1  \\\n",
       "0          1         1       1   \n",
       "1          2         1       1   \n",
       "2          3         1       1   \n",
       "3          4         1       0   \n",
       "4          5         1       2   \n",
       "...      ...       ...     ...   \n",
       "17038  27584        10       1   \n",
       "17039  27585        10       1   \n",
       "17040  27586        10       1   \n",
       "17041  27587        10       1   \n",
       "17042  27588        10       0   \n",
       "\n",
       "                                               EssayText Grading Scale  \n",
       "0      Task description: Data Set #1\\nPrompt—Acid Rai...        0 to 3  \n",
       "1      Task description: Data Set #1\\nPrompt—Acid Rai...        0 to 3  \n",
       "2      Task description: Data Set #1\\nPrompt—Acid Rai...        0 to 3  \n",
       "3      Task description: Data Set #1\\nPrompt—Acid Rai...        0 to 3  \n",
       "4      Task description: Data Set #1\\nPrompt—Acid Rai...        0 to 3  \n",
       "...                                                  ...           ...  \n",
       "17038  Task description: Data Set #10\\nPrompt—Doghous...        0 to 2  \n",
       "17039  Task description: Data Set #10\\nPrompt—Doghous...        0 to 2  \n",
       "17040  Task description: Data Set #10\\nPrompt—Doghous...        0 to 2  \n",
       "17041  Task description: Data Set #10\\nPrompt—Doghous...        0 to 2  \n",
       "17042  Task description: Data Set #10\\nPrompt—Doghous...        0 to 2  \n",
       "\n",
       "[17043 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 50\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and saving dataset to data/tokenized_data/tokenized_set1_train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce2bc2fc83640498c8f3a13acbb0121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1338 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1582821612624adeb47d523b86cf0311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1338 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and saving dataset to data/tokenized_data/tokenized_set1_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037d5abe5b6a41898dc2306c2ee886d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/334 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72ff0cd1a1244999f891970c68238f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/334 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and saving dataset to data/tokenized_data/tokenized_set2_train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a63fcdb9d8a43d09027c5c6156794ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1022 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6ca9e2c6d3455b84b315d91eedde84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1022 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and saving dataset to data/tokenized_data/tokenized_set2_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd47337a42024f40acf6da37bce63e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c0ecb731d24ca6bf1acf26aaf533fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and saving dataset to data/tokenized_data/tokenized_set3_train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9265377503f42f3a6cb41b021901b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1446 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88deddae58294605a76d47a66e2140e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1446 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and saving dataset to data/tokenized_data/tokenized_set3_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de1d6367f70485783bc223931ea6de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/362 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3cacb7b7ff4bc4b6db7bb18fd5e0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/362 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and saving dataset to data/tokenized_data/tokenized_set4_train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86fcf9ff867546318080756bd76556a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1326 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6b561ec0de4faaaefe23a4535ff8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1326 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and saving dataset to data/tokenized_data/tokenized_set4_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e0cb4ed33441c0bf99ce3573293eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/331 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea504b15af254ea688e9c4b4545d5f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/331 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and saving dataset to data/tokenized_data/tokenized_set5_train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bdd9ff5582e4738a157ed147f6ee798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1436 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2a71ad5a8a43a1b8928f081afa390e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1436 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and saving dataset to data/tokenized_data/tokenized_set5_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b217b464700e4c3e9383ad5399153eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/359 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ae1d47030940a0845564e3b4135d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/359 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and saving dataset to data/tokenized_data/tokenized_set6_train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d213a9a328e148df9b69a3fee97f696f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1438 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda7baab75a94b478bf4ca91a7153b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1438 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and saving dataset to data/tokenized_data/tokenized_set6_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3ed0f94724482aa11cd5c6fe749de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/359 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86cd222446941b292beb1ebbbd393ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/359 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and saving dataset to data/tokenized_data/tokenized_set7_train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbedb512201949fda923a5c618965b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1439 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0e1d6737c947989d81dbf56ab3b584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1439 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and saving dataset to data/tokenized_data/tokenized_set7_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a38b0941caa42f9b1e396df997021ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de7044c8e8b4ac2afbdc448ef2847f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and saving dataset to data/tokenized_data/tokenized_set8_train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3237a857d6749ecbcb8443c4d1fb67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1439 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f17cf3831f482bbc0f4dd399ad0482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1439 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and saving dataset to data/tokenized_data/tokenized_set8_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d281fc1bfd466d9836aa4c81dcf98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7959f8fdbb8549ea8f5f81ad5a451ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and saving dataset to data/tokenized_data/tokenized_set9_train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96e4ec3758d481b90f2a1f3d57e1781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1438 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19751414260a4d73b79ec6be616efa7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1438 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and saving dataset to data/tokenized_data/tokenized_set9_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2eb89261ce449d9bc924eeb86960fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04cd1fa9bd564748829a5dd809867b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and saving dataset to data/tokenized_data/tokenized_set10_train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11cc2f67c734308b486d4bf94515760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1312 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc7b6ea44b142559d998637e3444318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1312 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and saving dataset to data/tokenized_data/tokenized_set10_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bdc16ded7c448c8ae66bc5f7e0bdf1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/328 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1df30f50b2d9406397b8d09058dba0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/328 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/s5100534/.local/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2531' max='21350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2531/21350 29:37 < 3:40:28, 1.42 it/s, Epoch 5.93/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.983100</td>\n",
       "      <td>0.964497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.982600</td>\n",
       "      <td>0.972375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.962600</td>\n",
       "      <td>0.946157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.941000</td>\n",
       "      <td>0.950430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.900200</td>\n",
       "      <td>0.953919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_tokenized_train_datasets = []\n",
    "all_tokenized_val_datasets = []\n",
    "\n",
    "for essay_set in range(1, NUM_ESSAY_SETS):\n",
    "    \n",
    "    split_ratio = 0.8\n",
    "    \n",
    "    essay_set_train_data = train_data[train_data['EssaySet'] == essay_set].sample(frac=split_ratio)\n",
    "    \n",
    "    essay_set_validation_data = train_data[train_data['EssaySet'] == essay_set].drop(essay_set_train_data.index)\n",
    "    \n",
    "    train_dataset = Dataset.from_dict({\n",
    "        \"EssayText\" : essay_set_train_data[\"EssayText\"].values,\n",
    "        \"Id\": essay_set_train_data[\"Score1\"].values,\n",
    "        \"EssaySet\": essay_set_train_data[\"EssaySet\"].values,\n",
    "        \"Score1\": essay_set_train_data[\"Score1\"].values,\n",
    "    })\n",
    "    \n",
    "    validation_dataset = Dataset.from_dict({\n",
    "        \"EssayText\" : essay_set_validation_data[\"EssayText\"].values,\n",
    "        \"Id\": essay_set_validation_data[\"Score1\"].values,\n",
    "        \"EssaySet\": essay_set_validation_data[\"EssaySet\"].values,\n",
    "        \"Score1\": essay_set_validation_data[\"Score1\"].values,\n",
    "    })\n",
    "\n",
    "    if essay_set == 1:\n",
    "        num_of_labels = train_data['Score1'].nunique()\n",
    "        scoring_model = BertScoringModel(num_labels=num_of_labels)\n",
    "\n",
    "    tokenized_train_dataset = scoring_model.get_tokenized_dataset(\n",
    "        train_dataset, is_train=True, essay_set=essay_set\n",
    "    )\n",
    "    \n",
    "    tokenized_val_dataset = scoring_model.get_tokenized_dataset(\n",
    "        validation_dataset, is_train=False, essay_set=essay_set\n",
    "    )\n",
    "    \n",
    "    all_tokenized_train_datasets.append(tokenized_train_dataset)\n",
    "    all_tokenized_val_datasets.append(tokenized_val_dataset)\n",
    "\n",
    "combined_train_dataset = concatenate_datasets(all_tokenized_train_datasets)\n",
    "combined_val_dataset = concatenate_datasets(all_tokenized_val_datasets)\n",
    "\n",
    "evaluation_results = scoring_model.train(\n",
    "    combined_train_dataset, combined_val_dataset, essay_set='all_sets', \n",
    "    batch_size=batch_size, epochs=epochs, patience=patience\n",
    ")\n",
    "\n",
    "print(f\"Final evaluation results: {evaluation_results}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "best_model_path = \"best_models/bert-base-uncased_setall_sets/\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(best_model_path)\n",
    "    \n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def score_essay(essay_text):\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    inputs = tokenizer(\n",
    "            essay_text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predicted_score = torch.argmax(logits, dim=-1).item()\n",
    "    return predicted_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Predicted Score'] = test_data.progress_apply(lambda row: score_essay(row['EssayText']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('data/test_set_with_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essay Set 1: QWK = 0.76069976299373\n",
      "Essay Set 2: QWK = 0.6816282557106876\n",
      "Essay Set 3: QWK = 0.5194318405997238\n",
      "Essay Set 4: QWK = 0.6142497904442581\n",
      "Essay Set 5: QWK = 0.6168183788469874\n",
      "Essay Set 6: QWK = 0.7284598736546561\n",
      "Essay Set 7: QWK = 0.6582621901165655\n",
      "Essay Set 8: QWK = 0.5477517083193959\n",
      "Essay Set 9: QWK = 0.8039125437195256\n",
      "Essay Set 10: QWK = 0.6973165725244594\n",
      "Avg QWK: 0.6628530916929989\n"
     ]
    }
   ],
   "source": [
    "qwk_list = []\n",
    "\n",
    "test_set = pd.read_csv(\"data/test_set_with_predictions.csv\")\n",
    "for essay_set in range(1, NUM_ESSAY_SETS):\n",
    "\n",
    "    test_set_filtered = test_set[test_set['EssaySet'] == essay_set]\n",
    "\n",
    "    unique_labels = test_set_filtered['Score1'].nunique()\n",
    "    \n",
    "    qwk = quadratic_weighted_kappa(\n",
    "        test_set_filtered['Score1'], \n",
    "        test_set_filtered['Predicted Score'], \n",
    "        min_rating=0, \n",
    "        max_rating=unique_labels\n",
    "    )\n",
    "    \n",
    "    print(f\"Essay Set {essay_set}: QWK = {qwk}\")\n",
    "    qwk_list.append(qwk)\n",
    "\n",
    "print(\"Avg QWK:\", np.mean(qwk_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
